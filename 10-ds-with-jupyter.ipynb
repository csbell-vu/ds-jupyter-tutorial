{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An intro to using Python in Jupyter notebooks for data science\n",
    "## Common tasks and grammar of data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "**Overall purpose**: The purpose of these repository notebooks is to perform a classification task on the selected dataset to classify whether, according to some predictors, a person's income will exceed $50k.  The dataset includes several predictors, but the ones that we will use for classification are `hours-per-week` (how many hours are worked per week), `workclass` (broad category of the type of work performed by the person), and `age` (how old the person is, in years). \n",
    "\n",
    "**Notebook purpose**: This notebook will illustrate some data manipulation tasks, and show how the grammar of data manipulation \\[select, filter, mutate, summarise, arrange\\] is achieved through Pandas and Python.  Keep in mind that there are *many* ways to achieve a certain grammar operation, and the syntax in this notebook absolutely does not demonstrate the exhaustive set.  \n",
    "\n",
    "**Data**: In this notebook, we demonstrate a data science task on \"cleaned data\" using Pandas, a popular tool in Python for analyzing data.  Since the data we will use is rather small, it is included in the repository under the data folder.  The included dataset is a slightly modified version of the Census income dataset obtained from the [UC Irvine machine learning data repository](https://archive.ics.uci.edu/ml/datasets/adult).\n",
    "\n",
    "**Cleaning tasks**:  This dataset has leading spaces after the delimiter in the .CSV file, as well as some non-standard indications of missing values (`?`).  For simplication, all the rows with any NA are simply dropped.\n",
    "\n",
    "The cleaned data will be saved to the local data directory, and then used in the following notebook, which will show some common machine learning tasks using scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to R, we start our processing by importing the packages that we need.  We will use pandas for our processing, which provides functionality for manipulating tabular data and other data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import statements\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#magics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and viewing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#na_list = []\n",
    "na_list = ['?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "filename = 'data/adult_data.csv'\n",
    "df = pd.read_csv(filename, skipinitialspace=True, na_values=na_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a preview of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General info about the data\n",
    "df.info(null_counts=True) #But what does pandas consider to be null/na?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stats about the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count na values\n",
    "df.isnull().sum(skipna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look at the value counts for all of the columns: categorical histogram\n",
    "for x in df.columns:\n",
    "    if df[x].dtype=='object':\n",
    "        print('Col name: ', x, '\\n', df[x].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simplest approach if datset large enough: drop the missing values\n",
    "#Note: avoid performing operations on subsets of a data frame\n",
    "test = df.dropna(axis=0)\n",
    "print('# of rows of returned (test) data frame: ', len(test))\n",
    "print('# of rows of original (df) data frame: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "print('# of rows of original (df) data frame: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum(skipna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Can write out data frames as well as read them!\n",
    "out_filename = 'data/adult_clean.csv'\n",
    "df.to_csv(out_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select: choose data from the dataframe\n",
    "You can select rows and columns in a number of ways, but make sure you use each accessor method in the right way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select certain columns by name and/or index\n",
    "df['occupation'].head() #shorthand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use loc operator to access each \n",
    "df.loc[:, 'occupation'].head() #using loc operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loc operator for a list of columns\n",
    "df.loc[:, ['occupation', 'marital-status', 'relationship']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iloc operator accesses by integer value; select columns by their integer values\n",
    "df.iloc[:, [6,5,7]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select certain rows using loc by index NAME\n",
    "df.loc[0:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select certain rows using iloc by integer location\n",
    "df.iloc[0:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it yourself!  Fill in the code that would select the desired data for each comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Access the 'capital-gain' column  by name.  Can it you also do it using the integer location? (hint: iloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Access the first 5 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter: choose rows of data based on some criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we look at a boolean list that is returned by our filter\n",
    "nm_bools = df.loc[:, 'marital-status'] != 'Never-married'\n",
    "nm_bools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we use the boolean list to access the rows for which it is true, for all columns\n",
    "n_nm_df = df.loc[nm_bools, :]\n",
    "n_nm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the creation of the boolean list with the selection of the desired data\n",
    "n_np_df = df.loc[ df.loc[:, 'workclass'] == 'Private', :]\n",
    "n_np_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it yourself!  Fill in the code that would filter out the desired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select all rows where the relationship is husband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select all rows where the education is HS-grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select all rows where hours-per-week is greater than 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutate: Perform operations on columns to create another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just selection and indexing to simply create another column in the df\n",
    "df.loc[:, 'age_adj'] = df.loc[:, 'age'] + 1\n",
    "#df['age_adj'] = df['age'] + 1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??df.assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use assign for a more R-like feel; columns must have keyword syntax\n",
    "df = df.assign(signed_capital = df['capital-gain'] - df['capital-loss'])\n",
    "df.rename(columns={'signed_capital' : 'signed-capital'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use dynamically created columns within an assign function call to create other columns (dplyr-like piping) processing in Pandas 0.23.0.  Our current version is 0.20.3 on ACCRE for now.  If working with a new version of pandas, convert the cell below to `code` and try it out!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Perform pipeline-like behavior using previous computations in the computation for future computations.\n",
    "df = df.assign(hours_per_year = df['hours-per-week']*52,\n",
    "               hours_per_life = lambda y: y['hours_per_year'] * df['age'])\n",
    "df.rename(columns={ 'hours_per_year': 'hours-per-year',\n",
    "                   'hours_per_life': 'hours-per-life'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it yourself!  Fill in the code that would mutate out the desired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add a new column (hours-per-year) that calculates the hours worked per year based on the hours-per-week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add new column (fnlwgt_k) that divides fnlwgt by 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby and summarize: group items by some desired similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean capital-gain based on workclass\n",
    "workclass_count = df.groupby(['workclass']).count()\n",
    "workclass_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean capital-gain based on workclass and marital status\n",
    "work_rel_mean = df.groupby(['workclass', 'marital-status']).mean()\n",
    "work_rel_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(axis=0, numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it yourself!  Fill in the code that would groupby and summarize out the desired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Group by education-num and calculate the sum of the other numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Group by native-country and calculate the mean of the other numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrange: change the ordering of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort data according to age\n",
    "df.sort_values(by='age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='age', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['age', 'education-num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['age', 'education-num'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it yourself!  Fill in the code that would groupby and summarize out the desired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sort rows by capital-gain, and then by age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sort rows by native country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??pd.Series.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#You can plot directly using Pandas!  Pandas plots are based on the matplotlib library.\n",
    "df['education-num'].hist(bins=15)\n",
    "plt.title('Histogram of education-nums')\n",
    "plt.xlabel('Education-num')\n",
    "plt.ylabel('Frequency (counts)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workclass_pie_info = df.groupby('workclass').count().mode(axis=1)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.pie(x=workclass_pie_info.iloc[:,0], labels = workclass_pie_info.index, autopct='%2.2f%%')\n",
    "plt.axis('equal')\n",
    "plt.title('Types of work represented in the census sample')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
