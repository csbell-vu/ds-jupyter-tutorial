{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data science and Python in Juypter\n",
    "### A bootcamp tutorial on using Python in Jupyter notebooks for Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrate a data science task on cleaned data using Pandas, a popular tool for analyzing and modeling tabular data.  The data that we will use is provided by here, and is included in the repository for convenience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to R, we start our processing by importing the packages that we need.  We will use pandas for our processing, which provides functionality for manipulating tabular data and other data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#magics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and viewing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_list = []\n",
    "na_list = ['?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "filename = 'data/adult_data.csv'\n",
    "df = pd.read_csv(filename, skipinitialspace=True, na_values=na_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a preview of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(null_counts=True) #But what does pandas consider to be null/na?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count na values and/or replace them with other things\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the value counts for all of the columns: categorical histogram\n",
    "for x in df.columns:\n",
    "    if df[x].dtype=='object':\n",
    "        print('Col name: ', x, '\\n', df[x].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting data from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select certain columns by name\n",
    "occupation_info = df['occupation'] #shorthand\n",
    "occupation_info = df.loc[:, 'occupation'] #using loc operator\n",
    "occupation_info = df.loc[:, ['occupation', 'marital-status', 'relationship']] #select multiple columns using a list\n",
    "ocupation_info = df.iloc[:, [3,5,7]] #select columns using their integer location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select certain rows\n",
    "first_n_rows = df.loc[0:10, :] #select rows by index NAME\n",
    "first_n_rows = df.iloc[0:10, :] #select rows by integer location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select columns according to some criteria\n",
    "nm_bools = df.loc[:, 'marital-status'] != 'Never-married'\n",
    "n_nm_df = df.loc[nm_bools, :]\n",
    "n_nm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select and view data for all non-'Private' workclasses\n",
    "n_np_df = df.loc[ df.loc[:, 'workclass'] != 'Private']\n",
    "n_np_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simplest approach if datset large enough: drop the missing values\n",
    "test=df.dropna(axis=0)\n",
    "test.shape\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['salary-class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#You can also plot directly using Pandas.  Pandas plots are based on the matplotlib library.\n",
    "df['education-num'].hist(bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??pd.Series.hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling the data (Alt 1)\n",
    "In this step, we'll model the data using some parts of the data as predictors and one column as the response.  For the predictors, we will use \\[age, workclass, capital-gain, capital-loss, hours-per-week\\], and for the response, we will use salary-class.  Some of these variables will require some preprocessing to get them into a form suitable for a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide data into training and testing sets.  This is essential so that information that should not be known to the testing set is not known.\n",
    "\n",
    "#Split data into relevant portions\n",
    "data_y = df['salary-class']\n",
    "data_x = df[['age', 'hours-per-week', 'workclass']]\n",
    "\n",
    "ptrain_x, ptest_x, ptrain_y, ptest_y = train_test_split(data_x, data_y, train_size=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodings for predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode workclass; note that if we wanted to, we could one hot all of the categorical matrices\n",
    "wc_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "wc_1h = wc_encoder.fit_transform(ptrain_x['workclass'].to_frame())\n",
    "wc_df = pd.DataFrame(wc_1h, columns=wc_encoder.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(wc_df.shape)\n",
    "wc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale inputs to logistic regression\n",
    "num_scaler = StandardScaler()\n",
    "ns = num_scaler.fit_transform(ptrain_x[['age','hours-per-week']])\n",
    "ns_df = pd.DataFrame(ns, columns=['age', 'hours-per-week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ns_df.shape)\n",
    "ns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodings for responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary encode label\n",
    "sc_encoder = LabelEncoder()\n",
    "sc = sc_encoder.fit_transform(ptrain_y)\n",
    "train_y = pd.Series(sc, name='salary-class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.head()\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate all of the features together\n",
    "#feat_df = df[['age', 'capital-gain', 'capital-loss', 'hours-per-week']].copy()\n",
    "train_x = pd.concat([wc_df, ns_df], sort=False, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_x.shape)\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_y.shape)\n",
    "train_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a classifier (via logistic regression)\n",
    "lr_classifier = LogisticRegressionCV(class_weight='balanced', solver='lbfgs', max_iter = 1000, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train classifier via kfold cross validation\n",
    "lr_classifier.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use above encoding methods to create test set\n",
    "test_x = pd.concat( [pd.DataFrame(wc_encoder.transform(ptest_x['workclass'].to_frame()),\n",
    "                                 columns=wc_encoder.get_feature_names()),\n",
    "                     pd.DataFrame(num_scaler.transform(ptest_x[['age', 'hours-per-week']]),\n",
    "                                  columns = ['age', 'hours-per-week'])], axis=1)\n",
    "test_y = pd.Series(sc_encoder.transform(ptest_y), name='salary-class')\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(test_x.shape)\n",
    "test_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_y.shape)\n",
    "test_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the classifier on the held out test set\n",
    "pred_y = lr_classifier.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Can use a classification report to get other metrics:\n",
    "print(\"Classification report: \\n\", classification_report(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Investigate popular singular metrics\n",
    "roc_auc_score(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, visualization provides a more intuitive understanding of the results.  For a better vis of the confusion matrix, we can use the matplotlib and seaborn packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the confusion matrix of the result of the testing set\n",
    "conf_mat = confusion_matrix(test_y,pred_y)\n",
    "conf_mat_ratio = conf_mat/(pred_y.shape[0])\n",
    "print(\"Confusion matrix: \\n\", conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1,2,1) \n",
    "ax = sn.heatmap(pd.DataFrame(conf_mat, index=sc_encoder.classes_, columns=sc_encoder.classes_),\n",
    "          annot=True, fmt = \"d\", annot_kws={\"size\": 14}, cbar=False)\n",
    "ax.set_xlabel('Predicted class', fontsize=16);\n",
    "ax.set_ylabel('Actual class', fontsize=16);\n",
    "ax.set_title('Salary-class Confusion: Counts')\n",
    "\n",
    "plt.subplot(1,2,2) \n",
    "ax = sn.heatmap(pd.DataFrame(conf_mat_ratio, index=sc_encoder.classes_, columns=sc_encoder.classes_),\n",
    "          annot=True, fmt = \"0.2f\", annot_kws={\"size\": 14}, cbar=False)\n",
    "ax.set_xlabel('Predicted class', fontsize=16);\n",
    "ax.set_ylabel('Actual class', fontsize=16);\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "ax.set_title('Salary-class Confusion: Ratio');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling the Data (Alt 2)\n",
    "One extremely important function of sklearn is to provide pipelines.  This essentially defines a set of steps that should be taken for any data that will be input to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters of the pipeline\n",
    "num_preds = ['age', 'hours-per-week']\n",
    "cat_preds = ['workclass']\n",
    "res_var = ['salary-class']\n",
    "\n",
    "#Define steps to be done for each type of variable defined\n",
    "num_steps = [('scaler', StandardScaler())]\n",
    "cat_steps = [('encoder', OneHotEncoder(handle_unknown='ignore'))]\n",
    "res_steps = [('encoder', LabelEncoder())]\n",
    "\n",
    "#transfomers\n",
    "num_xformer = Pipeline(num_steps)\n",
    "cat_xformer = Pipeline(cat_steps)\n",
    "\n",
    "#Defined preprocessing steps\n",
    "preprocessor = ColumnTransformer(transformers=[('num', num_xformer, num_preds),\n",
    "                                              ('cat', cat_xformer, cat_preds)])\n",
    "\n",
    "#Create full pipeline steps\n",
    "lr_pipeline = Pipeline(steps = [('preprocessor', preprocessor),\n",
    "                               ('classifier', LogisticRegressionCV(class_weight='balanced', solver='lbfgs',\n",
    "                                                                   max_iter =1000, cv=5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into relevant portions\n",
    "data_y = df['salary-class']\n",
    "data_x = df[['age', 'hours-per-week', 'workclass']]\n",
    "\n",
    "ptrain_x, ptest_x, ptrain_y, ptest_y = train_test_split(data_x, data_y, train_size=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform encoding on train_y and test_y\n",
    "res_encoder = LabelEncoder()\n",
    "train_y = res_encoder.fit_transform(ptrain_y)\n",
    "test_y = res_encoder.transform(ptest_y)\n",
    "res_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform prediction on the data using the pipeline\n",
    "lr_pipeline.fit(ptrain_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_pipeline.predict(ptest_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at confusion matrix\n",
    "conf_mat = confusion_matrix(test_y, y_pred)\n",
    "conf_mat_ratio = conf_mat/(y_pred.shape[0])\n",
    "conf_mat = confusion_matrix(test_y,y_pred)\n",
    "print(\"Confusion matrix: \\n\", conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
